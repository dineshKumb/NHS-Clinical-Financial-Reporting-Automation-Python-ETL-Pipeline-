{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bdbdb7",
   "metadata": {},
   "source": [
    "# This code will Generate Fake dataset for this project\n",
    "\n",
    "\n",
    "### 1. 325 Financial files where each file will have 1-14 tabs. each tab represents one service\n",
    "### 2. 25 operation files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e817632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation completed successfully.\n",
      "Finance files saved to: C:\\Users\\Gauri\\Documents\\End to End Reporting Project\\finance\n",
      "Backend files saved to: C:\\Users\\Gauri\\Documents\\End to End Reporting Project\\backend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import os\n",
    "import Config\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# CONFIG\n",
    "# --------------------------------------------------------\n",
    "BASE_PATH = Config.BASE_RAW\n",
    "FINANCE_DIR = os.path.join(BASE_PATH, \"finance\")\n",
    "BACKEND_DIR = os.path.join(BASE_PATH, \"backend\")\n",
    "\n",
    "os.makedirs(FINANCE_DIR, exist_ok=True)\n",
    "os.makedirs(BACKEND_DIR, exist_ok=True)\n",
    "\n",
    "TOTAL_AREAS = 325\n",
    "TOTAL_SERVICES = 14\n",
    "TOTAL_BACKEND_FILES = 25   # 14 service-based + 11 failsafe\n",
    "\n",
    "services = [f\"Service_{i}\" for i in range(1, TOTAL_SERVICES + 1)]\n",
    "areas = list(range(1, TOTAL_AREAS + 1))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. FINANCE DATA (325 Excel files with multiple sheets)\n",
    "# --------------------------------------------------------\n",
    "for area in areas:\n",
    "    # Random services this area contains (3â€“14)\n",
    "    area_services = np.random.choice(services, size=np.random.randint(3, 15), replace=False)\n",
    "\n",
    "    # Create Excel writer per area\n",
    "    file_path = os.path.join(FINANCE_DIR, f\"finance_area_{area}.xlsx\")\n",
    "    with pd.ExcelWriter(file_path, engine=\"xlsxwriter\") as writer:\n",
    "\n",
    "        for service in area_services:\n",
    "            n_records = np.random.randint(50, 200)\n",
    "\n",
    "            df = pd.DataFrame({\n",
    "                \"transaction_id\": [fake.uuid4() for _ in range(n_records)],\n",
    "                \"area_id\": area,\n",
    "                \"service_type\": service,\n",
    "                \"transaction_amount\": np.random.uniform(50, 2000, size=n_records).round(2),\n",
    "                \"transaction_date\": [\n",
    "                    fake.date_between(start_date=\"-2y\", end_date=\"today\")\n",
    "                    for _ in range(n_records)\n",
    "                ],\n",
    "            })\n",
    "\n",
    "            df.to_excel(writer, sheet_name=service, index=False)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. BACKEND OPERATIONAL DATA (25 datasets)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# ---- 14 service-based backend files (primary operational datasets)\n",
    "for service in services:\n",
    "    n_records = 30000\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"record_id\": [fake.uuid4() for _ in range(n_records)],\n",
    "        \"area_id\": np.random.choice(areas, size=n_records),\n",
    "        \"service_type\": service,\n",
    "        \"units_processed\": np.random.randint(1, 500, size=n_records),\n",
    "        \"processing_cost\": np.random.uniform(20, 1000, size=n_records).round(2),\n",
    "        \"operation_date\": [\n",
    "            fake.date_between(start_date=\"-2y\", end_date=\"today\")\n",
    "            for _ in range(n_records)\n",
    "        ],\n",
    "    })\n",
    "\n",
    "    file_path = os.path.join(BACKEND_DIR, f\"backend_operations_{service}.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# ---- 11 failsafe/redundant operational datasets\n",
    "for i in range(TOTAL_BACKEND_FILES - TOTAL_SERVICES):\n",
    "    n_records = 3000\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"record_id\": [fake.uuid4() for _ in range(n_records)],\n",
    "        \"area_id\": np.random.choice(areas, size=n_records),\n",
    "        \"service_type\": np.random.choice(services, size=n_records),\n",
    "        \"units_processed\": np.random.randint(1, 500, size=n_records),\n",
    "        \"processing_cost\": np.random.uniform(20, 1000, size=n_records).round(2),\n",
    "        \"operation_date\": [\n",
    "            fake.date_between(start_date=\"-2y\", end_date=\"today\")\n",
    "            for _ in range(n_records)\n",
    "        ],\n",
    "    })\n",
    "\n",
    "    file_path = os.path.join(BACKEND_DIR, f\"backend_operations_failsafe_{i+1}.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Dataset generation completed successfully.\")\n",
    "print(f\"Finance files saved to: {FINANCE_DIR}\")\n",
    "print(f\"Backend files saved to: {BACKEND_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c00e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
